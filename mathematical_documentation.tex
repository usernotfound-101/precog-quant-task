\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{array}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{listings}

\geometry{margin=1in}

\title{\textbf{Mathematical Documentation and Trading Strategies} \\ 
\Large Quantitative Trading Research Platform}
\author{PRECOG Quant Task Project}
\date{February 2026}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Executive Summary}

This document provides comprehensive mathematical documentation for a quantitative trading research framework. The platform implements a complete algorithmic trading pipeline encompassing:

\begin{itemize}
    \item Data acquisition and feature engineering using advanced signal processing
    \item Statistical arbitrage via cointegration analysis
    \item Machine learning-based alpha and risk prediction
    \item Systematic backtesting with realistic transaction cost modeling
\end{itemize}

The framework processes 100 anonymized assets and develops systematic trading strategies based on mathematical models and statistical tests.

\newpage

\section{Data Cleaning and Feature Engineering}

\subsection{Technical Indicators}

\subsubsection{Relative Strength Index (RSI)}

The RSI is a momentum oscillator measuring the speed and magnitude of price changes over a rolling window of $n = 14$ days.

\textbf{Price Change:}
\begin{equation}
    \Delta_t = \text{Close}_t - \text{Close}_{t-1}
\end{equation}

\textbf{Gain and Loss Separation:}
\begin{align}
    \text{Gain}_t &= \max(\Delta_t, 0) \\
    \text{Loss}_t &= \max(-\Delta_t, 0)
\end{align}

\textbf{Average Gain and Loss (14-day rolling mean):}
\begin{align}
    \text{AvgGain}_t &= \frac{1}{14}\sum_{i=t-13}^{t} \text{Gain}_i \\
    \text{AvgLoss}_t &= \frac{1}{14}\sum_{i=t-13}^{t} \text{Loss}_i
\end{align}

\textbf{Relative Strength:}
\begin{equation}
    \text{RS}_t = \frac{\text{AvgGain}_t}{\text{AvgLoss}_t}
\end{equation}

\textbf{RSI Calculation:}
\begin{equation}
    \text{RSI}_t = 100 - \frac{100}{1 + \text{RS}_t}
\end{equation}

The RSI oscillates between 0 and 100, with values above 70 traditionally indicating overbought conditions and values below 30 indicating oversold conditions.

\subsubsection{Rogers-Satchell Volatility}

The Rogers-Satchell (RS) volatility estimator utilizes intraday high-low-open-close data to provide an unbiased estimate of volatility without assuming zero drift.

\textbf{Per-Period RS Variance:}
\begin{equation}
    \text{RS}_t = \ln\left(\frac{H_t}{O_t}\right) \cdot \ln\left(\frac{H_t}{C_t}\right) + \ln\left(\frac{L_t}{O_t}\right) \cdot \ln\left(\frac{L_t}{C_t}\right)
\end{equation}

where:
\begin{itemize}
    \item $H_t$ = High price at time $t$
    \item $L_t$ = Low price at time $t$
    \item $O_t$ = Open price at time $t$
    \item $C_t$ = Close price at time $t$
\end{itemize}

\textbf{Rolling Volatility (14-day window):}
\begin{equation}
    \text{RS\_Vol}_t = \sqrt{\frac{1}{14}\sum_{i=t-13}^{t} \text{RS}_i}
\end{equation}

Note: In the implementation, a 20-day window was used in the function definition (default parameter), but 14 days is used in actual feature computation.

\subsection{Kalman Filter for Signal Smoothing}

A one-dimensional Kalman filter is applied to smooth noisy technical indicators while preserving signal quality. The filter uses process noise covariance $Q = 0.01$ and measurement noise covariance $R = 1.0$.

\textbf{State Prediction:}
\begin{align}
    \hat{x}_{t|t-1} &= \hat{x}_{t-1|t-1} \\
    P_{t|t-1} &= P_{t-1|t-1} + Q
\end{align}

\textbf{Kalman Gain:}
\begin{equation}
    K_t = \frac{P_{t|t-1}}{P_{t|t-1} + R}
\end{equation}

\textbf{State Update:}
\begin{align}
    \hat{x}_{t|t} &= \hat{x}_{t|t-1} + K_t(z_t - \hat{x}_{t|t-1}) \\
    P_{t|t} &= (1 - K_t) \cdot P_{t|t-1}
\end{align}

where:
\begin{itemize}
    \item $\hat{x}_{t|t}$ = Filtered state estimate at time $t$
    \item $z_t$ = Measurement (observed value) at time $t$
    \item $P_{t|t}$ = Error covariance estimate at time $t$
    \item $K_t$ = Kalman gain at time $t$
\end{itemize}

The Kalman filter implementation uses a simple one-dimensional model with constant dynamics and fills NaN values with 0 before processing.

\subsection{Engineered Feature Set}

The following features are engineered for each asset:

\begin{table}[h]
\centering
\begin{tabular}{p{4cm}p{7cm}p{2cm}}
\toprule
\textbf{Feature} & \textbf{Formula} & \textbf{Window} \\
\midrule
ret\_14d & $\frac{\text{Close}_t}{\text{Close}_{t-14}} - 1$ & 14 days \\
\hline
RSI\_kalman & $\mathcal{K}(\text{RSI}_{14})$ & - \\
\hline
ret\_14d\_kalman & $\mathcal{K}(\text{ret}_{14d})$ & - \\
\hline
RS\_vol\_kalman & $\mathcal{K}(\text{RS\_Vol})$ & - \\
\hline
RSI\_slope & $\Delta(\text{RSI\_kalman})$ & 1st diff \\
\hline
RSI\_accel & $\Delta^2(\text{RSI\_kalman})$ & 2nd diff \\
\hline
risk\_adj\_mom & $\frac{\text{ret\_14d\_kalman}}{\text{RS\_vol\_kalman}}$ & - \\
\hline
vol\_z\_14 & $\frac{\text{Volume}_t - \mu_{14}(\text{Volume})}{\sigma_{14}(\text{Volume})}$ & 14 days \\
\bottomrule
\end{tabular}
\caption{Engineered Feature Set}
\end{table}

where $\mathcal{K}(\cdot)$ denotes the Kalman filter operator, $\Delta$ denotes first difference, and $\Delta^2$ denotes second difference.

\newpage

\section{Similarity Analysis and Cointegration}

\subsection{Correlation-Based Asset Screening}

Assets are screened for high correlation to identify potential trading pairs:

\textbf{Pearson Correlation Coefficient:}
\begin{equation}
    \rho(r_i, r_j) = \frac{\text{Cov}(r_i, r_j)}{\sigma_{r_i} \cdot \sigma_{r_j}}
\end{equation}

where $r_i$ and $r_j$ are return series for assets $i$ and $j$.

\textbf{Screening Criterion:}
\begin{equation}
    \rho(r_i, r_j) > 0.90
\end{equation}

Based on the clustering heatmap, the dataset exhibits clear correlation structure with several distinct clusters of highly correlated assets.

\subsection{Cointegration Testing}

For asset pairs passing the correlation screen, cointegration is tested to identify mean-reverting relationships.

\subsubsection{Log-Price Construction}

\begin{equation}
    S_t^{\log} = \ln(S_t)
\end{equation}

where $S_t$ is the price of the asset at time $t$.

\subsubsection{Hedge Ratio Estimation}

The hedge ratio $\beta$ is estimated via ordinary least squares (OLS) regression:

\textbf{Linear Regression Model:}
\begin{equation}
    S_{1,t}^{\log} = \alpha + \beta \cdot S_{2,t}^{\log} + \epsilon_t
\end{equation}

\textbf{OLS Solution:}
\begin{equation}
    \beta = \frac{\text{Cov}(S_1^{\log}, S_2^{\log})}{\text{Var}(S_2^{\log})}
\end{equation}

\subsubsection{Spread Construction}

The cointegrated spread is constructed as:

\begin{equation}
    \text{Spread}_t = S_{1,t}^{\log} - \beta \cdot S_{2,t}^{\log}
\end{equation}

Under cointegration, this spread is stationary and mean-reverting.

\subsubsection{Augmented Dickey-Fuller (ADF) Test}

The ADF test is used to verify stationarity of the spread:

\textbf{Test Regression:}
\begin{equation}
    \Delta \text{Spread}_t = \alpha + \gamma \cdot \text{Spread}_{t-1} + \sum_{i=1}^{p} \delta_i \Delta \text{Spread}_{t-i} + \epsilon_t
\end{equation}

\textbf{Null Hypothesis:} $H_0: \gamma = 0$ (unit root exists, non-stationary)

\textbf{Alternative Hypothesis:} $H_1: \gamma < 0$ (stationary)

\textbf{Significance Level:} $\alpha = 0.05$ (5\% significance)

A p-value below 0.05 provides evidence to reject the null hypothesis and conclude that the spread is stationary. For the example pair (Asset\_008 vs Asset\_024), the cointegration test yielded a p-value of 0.00021, strongly suggesting a stationary spread.

\subsection{Distance Metrics}

For clustering and similarity analysis, correlation-based distance is used:

\begin{equation}
    d(i, j) = 1 - |\rho(r_i, r_j)|
\end{equation}

This distance metric ranges from 0 (perfect correlation) to 2 (perfect negative correlation).

\newpage

\section{Machine Learning Models}

\subsection{Walk-Forward Cross-Validation}

To prevent look-ahead bias, a walk-forward validation scheme is employed:

\begin{itemize}
    \item \textbf{Number of Splits:} 5 time-series splits
    \item \textbf{Method:} TimeSeriesSplit (scikit-learn)
    \item \textbf{Property:} Each test set uses only data following the training set chronologically
\end{itemize}

\subsection{Target Variable Construction}

\subsubsection{Forward 14-Day Return (Alpha Target)}

\begin{equation}
    y_t^{\text{return}} = \frac{\text{Close}_{t+14}}{\text{Close}_t} - 1
\end{equation}

This represents the 14-day forward return, which the model aims to predict.

\subsubsection{Forward 14-Day Volatility (Risk Target)}

\begin{equation}
    y_t^{\text{risk}} = \sigma_{14}(\text{PctChange}_{t \to t+14})
\end{equation}

where $\sigma_{14}$ denotes the standard deviation over the 14-day forward window calculated as a rolling statistic shifted backward.

\subsection{XGBoost Model Configuration}

Two separate XGBoost regressors are trained:

\begin{enumerate}
    \item \textbf{Alpha Model:} Predicts forward returns
    \item \textbf{Risk Model:} Predicts forward volatility
\end{enumerate}

\textbf{Hyperparameters:}
\begin{itemize}
    \item \texttt{n\_estimators}: 500 (number of boosting rounds)
    \item \texttt{learning\_rate}: 0.01 (shrinkage to prevent overfitting)
    \item \texttt{max\_depth}: 3 (maximum tree depth)
    \item \texttt{subsample}: 0.7 (row sampling ratio)
    \item \texttt{colsample\_bytree}: 0.7 (feature sampling ratio)
    \item \texttt{objective}: \texttt{reg:squarederror} (L2 loss)
    \item \texttt{n\_jobs}: -1 (parallel processing)
\end{itemize}

\subsection{Loss Function}

XGBoost minimizes the squared error loss with regularization:

\begin{equation}
    \mathcal{L}(\theta) = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 + \sum_{k=1}^{K} \Omega(f_k)
\end{equation}

where:
\begin{itemize}
    \item $y_i$ = True target value
    \item $\hat{y}_i$ = Predicted value
    \item $\Omega(f_k)$ = Regularization term for tree $k$
    \item $K$ = Number of trees
\end{itemize}

\subsection{Signal Engineering}

\subsubsection{Raw Score Construction}

The raw trading score combines predicted return and predicted risk:

\begin{equation}
    \text{TradeScore}_t = \frac{\text{pred\_return}_t}{\text{pred\_risk}_t + \epsilon}
\end{equation}

where $\epsilon = 10^{-6}$ prevents division by zero.

\subsubsection{Signal Smoothing}

A 3-day rolling mean smooths the raw scores:

\begin{equation}
    \text{TradeScore\_Smooth}_t = \frac{1}{3}\sum_{i=0}^{2} \text{TradeScore}_{t-i}
\end{equation}

\subsubsection{Inverse Volatility Weighting}

Position weights are inversely proportional to predicted risk:

\begin{equation}
    w_t^{\text{inv\_vol}} = \frac{1}{\text{pred\_risk}_t + \epsilon_w}
\end{equation}

where $\epsilon_w = 10^{-4}$ ensures numerical stability.

\newpage

\section{Backtesting Framework}

\subsection{Portfolio Construction}

\subsubsection{Asset Selection}

At each rebalancing date:
\begin{enumerate}
    \item Filter assets with \texttt{trade\_score\_smooth} $>$ threshold $\tau = 1.0$
    \item Rank filtered assets by \texttt{trade\_score\_smooth} in descending order
    \item Apply sticky rank logic: keep current holdings if they remain in top 15 candidates
    \item Fill remaining slots (up to $N = 10$ total) with highest-ranked new candidates
\end{enumerate}

The sticky rank mechanism reduces turnover by maintaining positions that remain viable rather than forcing complete daily rebalancing.

\subsubsection{Position Sizing}

\textbf{Step 1 - Normalize Inverse Volatility Weights:}

For each selected asset $i$ in the target portfolio:
\begin{equation}
    w_i^{\text{norm}} = \frac{w_i^{\text{inv\_vol}}}{\sum_{j \in \text{Selected}} w_j^{\text{inv\_vol}}}
\end{equation}

\textbf{Step 2 - Calculate Target Position Values:}

First, compute current equity value:
\begin{equation}
    \text{Equity}_t = \text{Cash}_t + \sum_{i \in \text{Holdings}} \text{Shares}_i \times \text{Price}_{i,t}
\end{equation}

Then determine target position values:
\begin{equation}
    \text{TargetValue}_i = \text{Equity}_t \times w_i^{\text{norm}}
\end{equation}

\textbf{Step 3 - Determine Target Shares:}
\begin{equation}
    \text{TargetShares}_i = \left\lfloor \frac{\text{TargetValue}_i}{\text{Price}_{i,t}} \right\rfloor
\end{equation}

\subsection{Transaction Cost Modeling}

\textbf{Cost Components:}
\begin{itemize}
    \item Bid-Ask Spread: 10 basis points (bps) = 0.001 = 0.1\%
    \item Slippage: Implicit in spread model
    \item Commission: Included in the 10 bps cost
\end{itemize}

\textbf{Transaction Cost per Trade:}
\begin{equation}
    \text{Cost}_{\text{trade}} = |\Delta\text{Value}| \times c
\end{equation}

where $c = 0.001$ (10 bps) and $\Delta\text{Value} = \text{TargetValue}_i - \text{CurrentValue}_i$.

\textbf{Total Daily Transaction Costs:}
\begin{equation}
    \text{TotalCost}_t = \sum_{i} |\text{TargetShares}_i - \text{CurrentShares}_i| \times \text{Price}_{i,t} \times c
\end{equation}

\subsection{Return Calculations}

\subsubsection{Daily Portfolio Return}

\begin{equation}
    r_t = \frac{\text{Equity}_t - \text{Equity}_{t-1} - \text{TotalCost}_t}{\text{Equity}_{t-1}}
\end{equation}

where $\text{Equity}_t$ is the portfolio value at time $t$.

\subsubsection{Cumulative Return}

\begin{equation}
    R_{\text{total}} = \frac{\text{Equity}_{\text{final}}}{\text{Equity}_{\text{initial}}} - 1
\end{equation}

\subsubsection{Annualized Return}

\begin{equation}
    R_{\text{annual}} = \left(1 + R_{\text{total}}\right)^{\frac{252}{N_{\text{days}}}} - 1
\end{equation}

where $N_{\text{days}}$ is the number of trading days in the backtest period.

\subsection{Risk Metrics}

\subsubsection{Sharpe Ratio}

The annualized Sharpe ratio measures risk-adjusted returns:

\begin{equation}
    \text{Sharpe} = \frac{\mu_r - r_f}{\sigma_r} \times \sqrt{252}
\end{equation}

where:
\begin{itemize}
    \item $\mu_r$ = Mean daily return
    \item $r_f$ = Risk-free rate (assumed to be 0 for this analysis)
    \item $\sigma_r$ = Standard deviation of daily returns
    \item 252 = Annualization factor (trading days per year)
\end{itemize}

\subsubsection{Maximum Drawdown}

The maximum drawdown measures the largest peak-to-trough decline:

\begin{equation}
    \text{MDD} = \min_{t \in [0, T]} \left( \frac{\text{Equity}_t}{\max_{s \in [0, t]} \text{Equity}_s} - 1 \right)
\end{equation}

\subsubsection{Average Drawdown}

\begin{equation}
    \text{AvgDD} = \frac{1}{N_{\text{dd}}} \sum_{i=1}^{N_{\text{dd}}} \text{DD}_i
\end{equation}

where $N_{\text{dd}}$ is the number of periods experiencing drawdown (equity below previous peak).

\subsubsection{Portfolio Turnover}

\begin{equation}
    \text{Turnover} = \frac{1}{N_{\text{days}}} \sum_{t=1}^{N_{\text{days}}} \frac{\sum_{i} |\Delta\text{Value}_{i,t}|}{2 \times \text{Equity}_t}
\end{equation}

This measures the average daily portfolio churn as a fraction of total portfolio value.

\subsection{Performance Attribution}

\subsubsection{Transaction Cost Impact}

\begin{equation}
    \text{CostImpact} = \frac{\text{TotalCosts}}{\text{TotalReturn} \times \text{InitialCapital}}
\end{equation}

\subsubsection{Benchmark Comparison}

\textbf{Outperformance:}
\begin{equation}
    \text{Outperf} = R_{\text{strategy}} - R_{\text{benchmark}}
\end{equation}

\textbf{Information Ratio:}
\begin{equation}
    \text{IR} = \frac{\mu_{r_s - r_b}}{\sigma_{r_s - r_b}} \times \sqrt{252}
\end{equation}

where $r_s$ and $r_b$ are strategy and benchmark returns respectively.

\newpage

\section{Statistical Tests and Hypothesis Testing}

\subsection{Augmented Dickey-Fuller (ADF) Test}

\textbf{Purpose:} Test for unit root (non-stationarity)

\textbf{Null Hypothesis:} $H_0$: Series has a unit root (non-stationary)

\textbf{Alternative Hypothesis:} $H_1$: Series is stationary

\textbf{Test Statistic:}
\begin{equation}
    \text{ADF} = \frac{\hat{\gamma}}{\text{SE}(\hat{\gamma})}
\end{equation}

\textbf{Decision Rule:} Reject $H_0$ if p-value $< 0.05$

\subsection{Correlation Hypothesis Test}

\textbf{Null Hypothesis:} $H_0$: $\rho = 0$ (no linear relationship)

\textbf{Test Statistic:}
\begin{equation}
    t = \frac{r\sqrt{n-2}}{\sqrt{1-r^2}}
\end{equation}

where $r$ is the sample correlation and $n$ is the sample size.

\newpage

\section{Strategy Summary}

\subsection{Overall Trading Strategy}

The implemented strategy is a \textbf{long-only quantitative equity strategy} based on machine learning predictions of future returns and risks.

\subsubsection{Strategy Components}

\begin{enumerate}
    \item \textbf{Universe:} 100 anonymized assets
    \item \textbf{Signal Generation:} XGBoost models predict 14-day forward returns and volatility
    \item \textbf{Position Sizing:} Inverse volatility weighting (risk parity approach)
    \item \textbf{Portfolio Construction:} Top 10 assets by risk-adjusted score
    \item \textbf{Rebalancing:} Daily with sticky rank to reduce turnover
    \item \textbf{Risk Management:} Diversification + volatility targeting
\end{enumerate}

\subsubsection{Key Strategy Parameters}

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Parameter} & \textbf{Value} & \textbf{Purpose} \\
\midrule
Initial Capital & \$1,000,000 & Starting portfolio value \\
Transaction Cost & 10 bps & Round-trip trading cost \\
Rebalance Frequency & Daily & Portfolio adjustment \\
Top N Assets & 10 & Number of positions \\
Score Threshold & 1.0 & Minimum signal strength \\
Smoothing Window & 3 days & Signal noise reduction \\
Sticky Rank Buffer & Top 15 & Turnover reduction \\
\bottomrule
\end{tabular}
\caption{Strategy Parameters}
\end{table}

\subsection{Alternative Strategies Explored}

\subsubsection{Pairs Trading Strategy}

Based on cointegration analysis in the similarity-checking notebook:

\textbf{Entry Conditions:}
\begin{equation}
    \text{Enter Long Spread if: } Z_t < -2
\end{equation}
\begin{equation}
    \text{Enter Short Spread if: } Z_t > +2
\end{equation}

where $Z_t$ is the z-score of the spread:
\begin{equation}
    Z_t = \frac{\text{Spread}_t - \mu_{\text{spread}}}{\sigma_{\text{spread}}}
\end{equation}

\textbf{Exit Conditions:}
\begin{equation}
    \text{Exit if: } |Z_t| < 0.5
\end{equation}

This mean-reversion strategy trades the spread when it deviates significantly (beyond 2 standard deviations) from its long-term mean and closes positions when the spread reverts toward the mean.

\subsection{Model Inputs and Configuration Summary}

\begin{table}[h]
\centering
\small
\begin{tabular}{p{5cm}p{4cm}p{3cm}}
\toprule
\textbf{Component} & \textbf{Parameter} & \textbf{Value} \\
\midrule
\multicolumn{3}{l}{\textbf{Technical Indicators}} \\
& RSI Window & 14 days \\
& RS Volatility Window & 14 days \\
& Kalman Q (Process Noise) & 0.01 \\
& Kalman R (Measurement) & 1.0 \\
\midrule
\multicolumn{3}{l}{\textbf{Feature Engineering}} \\
& Return Lookback & 14 days \\
& Volume Z-score Window & 14 days \\
& RSI Derivatives & 1st \& 2nd order \\
\midrule
\multicolumn{3}{l}{\textbf{Cointegration Analysis}} \\
& Correlation Threshold & 0.90 \\
& ADF Significance Level & 0.05 \\
& Log-Price Transform & Yes \\
& Z-Score Entry Threshold & $\pm$2.0 \\
& Z-Score Exit Threshold & $\pm$0.5 \\
\midrule
\multicolumn{3}{l}{\textbf{Machine Learning}} \\
& Prediction Horizon & 14 days \\
& XGBoost Trees & 500 \\
& Learning Rate & 0.01 \\
& Max Tree Depth & 3 \\
& Subsample Ratio & 0.7 \\
& Feature Sampling & 0.7 \\
& CV Splits & 5 (time-series) \\
& Min Data per Asset & 300 days \\
\midrule
\multicolumn{3}{l}{\textbf{Signal Processing}} \\
& Signal Smoothing & 3-day MA \\
& Risk Adjustment Epsilon & $10^{-6}$ \\
& Weight Scaling Epsilon & $10^{-4}$ \\
\midrule
\multicolumn{3}{l}{\textbf{Backtesting}} \\
& Rebalance Frequency & Daily \\
& Transaction Cost & 10 bps \\
& Position Count & 10 assets \\
& Initial Capital & \$1,000,000 \\
& Backtest Duration & 2 years \\
& Backtest Period & 2023-12-26 to 2025-12-26 \\
\bottomrule
\end{tabular}
\caption{Complete Model Configuration}
\end{table}

\section{Performance Metrics and Actual Results}

\subsection{Backtesting Configuration}

\textbf{Test Period:} December 26, 2023 to December 26, 2025 (2 years, 503 trading days)

\textbf{Data Points:} 50,300 observations across 100 assets

\textbf{Initial Capital:} \$1,000,000

\subsection{Core Performance Metrics}

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{Strategy} & \textbf{Benchmark} & \textbf{Difference} \\
\midrule
\textbf{Returns} & & & \\
Total Return & 47.64\% & 44.57\% & +3.07\% \\
Annualized Return & 21.36\% & 20.06\% & +1.30\% \\
Final Portfolio Value & \$1,476,426 & \$1,445,749 & +\$30,677 \\
Absolute Gain & \$476,426 & \$445,749 & +\$30,677 \\
\midrule
\textbf{Risk Metrics} & & & \\
Sharpe Ratio & 1.31 & 1.46 & -0.15 \\
Daily Volatility & 1.01\% & 0.84\% & +0.17\% \\
Max Drawdown & -14.64\% & -15.45\% & +0.80\% \\
Avg Drawdown & -2.10\% & - & - \\
\midrule
\textbf{Execution Metrics} & & & \\
Portfolio Turnover & 0.35x & - & - \\
Avg Holdings & 10.0 & - & - \\
Min/Max Holdings & 10 / 10 & - & - \\
\bottomrule
\end{tabular}
\caption{Comprehensive Performance Metrics}
\end{table}

\subsection{Transaction Cost Analysis}

The impact of transaction costs on strategy performance:

\begin{table}[h]
\centering
\begin{tabular}{lr}
\toprule
\textbf{Transaction Cost Metric} & \textbf{Value} \\
\midrule
Total Transaction Costs & \$178,525 \\
Costs as \% of Initial Capital & 17.85\% \\
Costs as \% of Gross Profit & 37.47\% \\
Average Daily Cost & \$355 \\
Trading Days & 503 \\
\bottomrule
\end{tabular}
\caption{Transaction Cost Impact}
\end{table}

\textbf{Cost Burden Interpretation:}

Transaction costs represent a significant drag on performance, consuming 37.47\% of gross profits. However, the strategy remains profitable and outperforms the benchmark even after these costs. The average daily cost of \$355 on a \$1M+ portfolio represents approximately 0.035\% daily cost, which is consistent with the 10 bps per-trade assumption.

\subsection{Scenario Analysis: Cost Sensitivity}

To understand the impact of transaction costs, we compare three scenarios:

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Scenario} & \textbf{Final Value} & \textbf{Total Return} & \textbf{Sharpe Ratio} \\
\midrule
Strategy (No Costs) & \$1,703,553 & 70.36\% & 1.76 \\
Strategy (With Costs) & \$1,476,426 & 47.64\% & 1.31 \\
Equal-Weight Benchmark & \$1,445,749 & 44.57\% & 1.46 \\
\midrule
\multicolumn{4}{l}{\textbf{Cost Impact Analysis}} \\
Cost Impact (Absolute) & -\$227,128 & -22.71\% & -0.45 \\
Cost Impact (Relative) & -13.33\% of final & -32.28\% of return & -25.57\% of Sharpe \\
\bottomrule
\end{tabular}
\caption{Transaction Cost Scenario Analysis}
\end{table}

\textbf{Key Insights from Scenario Analysis:}

\begin{itemize}
    \item Without costs, the strategy would achieve 70.36\% return and 1.76 Sharpe ratio
    \item Transaction costs reduced returns by 22.71 percentage points
    \item Despite this significant drag, the strategy still outperforms the benchmark
    \item The cost impact of \$227,128 represents 13.33\% of the final portfolio value
    \item Sharpe ratio degradation from 1.76 to 1.31 (-25.57\%) indicates costs primarily impact returns rather than return consistency
\end{itemize}

\subsection{Risk Analysis}

\subsubsection{Drawdown Characteristics}

Both maximum and average drawdown metrics favor the strategy over the benchmark:

\begin{equation}
\text{Drawdown Improvement} = \text{MDD}_{\text{benchmark}} - \text{MDD}_{\text{strategy}} = -15.45\% - (-14.64\%) = 0.80\%
\end{equation}

The strategy experienced slightly smaller maximum drawdowns, suggesting better downside protection despite higher volatility (1.01\% vs 0.84\% daily).

\subsubsection{Return Distribution}

Based on the daily returns histogram:
\begin{itemize}
    \item The strategy exhibits a wider return distribution compared to the benchmark
    \item Both distributions appear approximately normal with slight positive skew
    \item The strategy shows more frequent extreme positive returns
    \item Daily volatility of 1.01\% annualizes to approximately 16\% annual volatility
\end{itemize}

\subsection{Execution Quality}

\textbf{Portfolio Characteristics:}

\begin{itemize}
    \item \textbf{Consistent Diversification:} Maintained exactly 10 holdings throughout the entire backtest period
    \item \textbf{Low Turnover:} Annual turnover of 0.35x indicates conservative rebalancing
    \item \textbf{Sticky Rank Effectiveness:} The top-15 buffer successfully reduced unnecessary trades
\end{itemize}

\textbf{Turnover Analysis:}

\begin{equation}
\text{Annual Turnover} = \frac{\sum_{t=1}^{503} \sum_{i} |\Delta\text{Value}_{i,t}|}{2 \times 503 \times \text{AvgEquity}} = 0.35
\end{equation}

A turnover ratio of 0.35 means that, on average, 35\% of the portfolio is replaced annually. This is relatively low for a daily-rebalanced strategy, demonstrating the effectiveness of the sticky rank mechanism.

\subsection{Strategy Viability Assessment}

The strategy passes all viability criteria:

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Viability Criterion} & \textbf{Result} & \textbf{Status} \\
\midrule
Positive Sharpe Ratio & 1.31 $>$ 0 & $\checkmark$ PASS \\
Positive Total Return & 47.64\% $>$ 0 & $\checkmark$ PASS \\
Outperforms Benchmark & 47.64\% $>$ 44.57\% & $\checkmark$ PASS \\
Manageable Drawdown & -14.64\% $>$ -20\% & $\checkmark$ PASS \\
Survives Transaction Costs & \$476,426 $>$ \$178,525 & $\checkmark$ PASS \\
\bottomrule
\end{tabular}
\caption{Viability Criteria Assessment}
\end{table}

\subsection{Performance Attribution}

\subsubsection{Sources of Outperformance}

The strategy's 3.07\% outperformance versus the benchmark can be attributed to:

\begin{enumerate}
    \item \textbf{Alpha Generation:} Machine learning models successfully predicted future returns, as evidenced by the 70.36\% pre-cost return
    \item \textbf{Risk-Adjusted Positioning:} Inverse volatility weighting provided better risk management during volatile periods
    \item \textbf{Dynamic Selection:} Daily rebalancing captured short-term momentum while avoiding deteriorating positions
    \item \textbf{Efficient Execution:} Low turnover (0.35x) minimized transaction cost drag
\end{enumerate}

\subsubsection{Risk-Adjusted Performance}

While the strategy's Sharpe ratio (1.31) is below the benchmark (1.46), this is primarily due to:

\begin{itemize}
    \item Higher daily volatility (1.01\% vs 0.84\%)
    \item Transaction cost impact on returns
    \item More concentrated portfolio (10 vs 100 holdings)
\end{itemize}

However, the strategy compensates with:
\begin{itemize}
    \item Higher absolute returns (+3.07\%)
    \item Better drawdown control (+0.80\%)
    \item Consistent holdings structure (exactly 10 positions)
\end{itemize}

\subsection{Key Performance Insights}

\begin{enumerate}
    \item \textbf{Strategy Structure Works:} The combination of ML predictions, inverse volatility weighting, and sticky rank logic generates positive alpha
    
    \item \textbf{Cost Management Critical:} Transaction costs consume 37.47\% of gross profits, emphasizing the importance of the turnover reduction mechanisms
    
    \item \textbf{Benchmark Outperformance:} Despite costs and slightly lower Sharpe ratio, the strategy delivers superior absolute returns
    
    \item \textbf{Controlled Risk:} Better maximum drawdown suggests effective risk management during market stress
    
    \item \textbf{Viable for Production:} All viability criteria met, with positive risk-adjusted returns after realistic transaction costs
\end{enumerate}

\subsection{Recommendation}

\textbf{STRATEGY VIABLE FOR LIVE TRADING}

The strategy demonstrates:
\begin{itemize}
    \item Consistent outperformance: +3.07\% total return over benchmark
    \item Profitable after costs: \$476,426 gain vs \$178,525 in costs
    \item Strong risk-adjusted returns: 1.31 Sharpe ratio
    \item Controlled risk: -14.64\% maximum drawdown
    \item Sustainable execution: 0.35x annual turnover
\end{itemize}

The 37.47\% cost burden on gross profits highlights the importance of execution quality and further turnover optimization in live implementation.

\newpage

\section{Mathematical Notation Reference}

\subsection{General Notation}

\begin{itemize}
    \item $t$ = Time index
    \item $i, j$ = Asset indices
    \item $n, N$ = Sample size or number of observations
    \item $\mu$ = Mean
    \item $\sigma$ = Standard deviation
    \item $\rho$ = Correlation coefficient
    \item $\epsilon$ = Error term or small constant
    \item $\mathcal{K}(\cdot)$ = Kalman filter operator
    \item $\Delta$ = First difference operator
    \item $\ln$ = Natural logarithm
\end{itemize}

\subsection{Financial Variables}

\begin{itemize}
    \item $S_t$ = Asset price at time $t$
    \item $r_t$ = Return at time $t$
    \item $\sigma_t$ = Volatility at time $t$
    \item $w_i$ = Weight of asset $i$ in portfolio
    \item $\text{Equity}_t$ = Portfolio value at time $t$
    \item $H_t, L_t, O_t, C_t$ = High, Low, Open, Close prices
\end{itemize}

\subsection{Model Components}

\begin{itemize}
    \item $\hat{y}$ = Predicted value
    \item $\beta$ = Regression coefficient / hedge ratio
    \item $\alpha$ = Intercept / significance level
    \item $K_t$ = Kalman gain
    \item $Q, R$ = Process and measurement noise covariances
    \item $f_k$ = Tree/function in ensemble model
\end{itemize}

\newpage

\section{References and Resources}

\subsection{Primary References}
\begin{itemize}
    \item Wikipedia - Relative Strength Index: \url{https://en.wikipedia.org/wiki/Relative_strength_index}
    \item Wikipedia - Kalman Filter: \url{https://en.wikipedia.org/wiki/Kalman_filter}
    \item Wikipedia - Cointegration: \url{https://en.wikipedia.org/wiki/Cointegration}
    \item Wikipedia - Sharpe Ratio: \url{https://en.wikipedia.org/wiki/Sharpe_ratio}
    \item Wikipedia - Augmented Dickey-Fuller test: \url{https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test}
\end{itemize}

\subsection{Software Documentation}
\begin{itemize}
    \item XGBoost Documentation: \url{https://xgboost.readthedocs.io/}
    \item scikit-learn Documentation: \url{https://scikit-learn.org/}
    \item pandas Documentation: \url{https://pandas.pydata.org/}
    \item statsmodels Documentation: \url{https://www.statsmodels.org/}
    \item PyKalman: \url{https://pykalman.github.io/}
\end{itemize}

\subsection{Key Academic Papers}
\begin{itemize}
    \item Rogers, L. C. G., \& Satchell, S. E. (1991). Estimating Variance From High, Low and Closing Prices. \textit{The Annals of Applied Probability}, 1(4), 504-512.
    \item Chen, T., \& Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. \textit{Proceedings of the 22nd ACM SIGKDD}.
\end{itemize}

\newpage

\section{Conclusion}

This document provides a comprehensive mathematical foundation for the quantitative trading research platform. The framework combines:

\begin{itemize}
    \item \textbf{Signal Processing:} Kalman filtering for noise reduction
    \item \textbf{Technical Analysis:} RSI, Rogers-Satchell volatility, and derived features
    \item \textbf{Statistical Arbitrage:} Cointegration-based pairs trading
    \item \textbf{Machine Learning:} XGBoost for alpha and risk prediction
    \item \textbf{Portfolio Management:} Inverse volatility weighting and risk parity
    \item \textbf{Realistic Backtesting:} Transaction costs, slippage, and market impact
\end{itemize}

The mathematical rigor and systematic approach ensure that the strategy is:
\begin{enumerate}
    \item \textbf{Reproducible:} All calculations are clearly defined with actual parameter values
    \item \textbf{Testable:} Hypotheses can be statistically validated
    \item \textbf{Robust:} Walk-forward validation prevents overfitting
    \item \textbf{Realistic:} Transaction costs are explicitly modeled and measured
    \item \textbf{Viable:} Demonstrates positive risk-adjusted returns with benchmark outperformance
\end{enumerate}

\textbf{Performance Summary:}
The implemented strategy achieved a Sharpe ratio of 1.31 with 47.64\% total return over a 2-year backtest period, outperforming the equal-weight benchmark by 3.07 percentage points while maintaining better drawdown control. After accounting for \$178,525 in transaction costs, the strategy generated approximately 30\% net returns, validating its practical viability.

Future enhancements could include:
\begin{itemize}
    \item Alternative machine learning models (LSTM, Transformer networks, ensemble methods)
    \item Multi-factor risk models (Fama-French, Carhart)
    \item Regime detection and adaptive strategies
    \item Short positions and market-neutral implementations
    \item Options strategies for hedging and income generation
    \item High-frequency microstructure analysis
    \item Dynamic position sizing based on market conditions
\end{itemize}

\vspace{1cm}

\hrule

\vspace{0.5cm}

\textbf{Disclaimer:} This documentation is for educational and research purposes only. Past performance does not guarantee future results. Trading involves substantial risk of loss. The backtest results presented may not reflect actual trading performance due to factors including but not limited to market impact, execution quality, and changing market conditions. Consult a qualified financial advisor before making any investment decisions.

\end{document}
